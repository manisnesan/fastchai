{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kick Start the Bulk Labeling using Embeddings\n",
    "\n",
    "Contributor: Manikandan Sivanesan\n",
    "\n",
    "## Elevator Pitch\n",
    "\n",
    "- For Text Classification problems in Machine Learning projects, it is essential to have a good labeled datasets to create an accurate model.\n",
    "- Eg: for sentiment analysis in movie review, you need labels a given review as positive, negative, neutral\n",
    "- In RedHat, when cases comes in we need a way to identify the common trends in the cases to improve product and for support resource allocation.\n",
    "- We create rules using keyword based heuristics. Eg: 'email' keyword with Services sbr in RHEL product, then the case belongs to email topic.\n",
    "- Challenge is there can be more than 10 tags per sbr. It is hard to scale this approach.  \n",
    "- In this hackday, evaluate a tool that can speed up this process using embeddings and bulk label to curate subsets of the dataset.\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Evaluate the bulk tool\n",
    "- Create embeddings for ansible dataset\n",
    "- Visualize the cluster embeddings of different topics.\n",
    "\n",
    "## Background and Technologies\n",
    "\n",
    "- sentence transformers package to create the embeddings\n",
    "- paraphrase-MiniLM-L6-v2 model to create 768 dimensions\n",
    "- UMAP - Reduce the higher dimensions to two dimensions for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Youtube: Tools to Improve Training Data - Vincent Warmerdam - Talking Language AI Ep 2](https://youtu.be/KRQJDLyc1uM?si=fjAF2jUJa3yM9u5R) : Vincent Warmerdam builds a lot of NLP tools (https://github.com/koaning). Many of these tools target the scikit-learn ecosystem and there's a theme of labeling across many of them. A recent focus of his stack of tools is to improve training data. In this video, Vincent and Jay discuss a few of these tools and show how they work together. \n",
    "  - Human-learn: a toolkit to build human-based scikit-learn components\n",
    "  - Doubtlab: a toolkit to help find doubtful labels in data\n",
    "  - Embetter: A library that makes it very easy to use embeddings in scikit-learn\n",
    "  - [Bulk](https://github.com/koaning/bulk): a library that uses embeddings to leverage bulk labeling\n",
    "\n",
    "- We are specifically exploring the tool [Bulk](https://github.com/koaning/bulk): a library that uses embeddings to leverage bulk labeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings for dataset and reduce the dimensionality for visual exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bc0f8e2ccf4037954e269957a4d3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61035fea77a4a78a7e13f511e65f737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c45a18256f45a6a7cb6238a117a5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd63cc53ad2c499b89e2b20602e66990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374057fe72f649e2a58cb79e68776328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f85392a659e480da53d1ba3babb81ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f85ddccedd46c282f3a8c96a111665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d772a7faf7b41b0997226b3b5b97877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d1a1efd7924eaba70f9e68424cecf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ec3ff8b57a4a71a85cd8ab1c9b984b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9192444ff8dd4c319fc36a26a0c7f82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34e2b425ca1448a8ec88b0919c586b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msivanes/miniconda3/envs/fastchai/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Load the universal sentence encoder\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('customer_support.csv')\n",
    "sentences = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the embeddings\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the embeddings\n",
    "umap = UMAP(n_components=2) # UMAP is a dimensionality reduction algorithm to reduce the embeddings from 768 to 2\n",
    "X_tfm = umap.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the coordinates\n",
    "df['x'] = X_tfm[:,0]\n",
    "df['y'] = X_tfm[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('customer_support_embeddings_visual_ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the learning on Ansible Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msivanes/miniconda3/envs/fastchai/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Load the universal sentence encoder\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/home/msivanes/0Work/routing/garlock/data/interim'\n",
    "ans_df = pd.read_feather(f'{BASE}/ansible_labeled_dataset.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_2d(df):\n",
    "    sentences = df['text']\n",
    "    embeddings = model.encode(sentences)     # Calculate the embeddings\n",
    "    umap = UMAP(n_components=2) # UMAP is a dimensionality reduction algorithm to reduce the embeddings from 768 to 2\n",
    "    X_tfm = umap.fit_transform(embeddings)\n",
    "    df['x'], df['y'] = X_tfm[:,0], X_tfm[:,1]\n",
    "    return df\n",
    "\n",
    "ans_df['text'] = ans_df['case_summary'] # text is a required colu,m and using case summary for now\n",
    "ans_df = embed_2d(ans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>case_summary</th>\n",
       "      <th>case_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02551134</td>\n",
       "      <td>Ansible Tower Installation Issue</td>\n",
       "      <td>installation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02551460</td>\n",
       "      <td>Is there a way to provide permission to invent...</td>\n",
       "      <td>api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02551667</td>\n",
       "      <td>Need assistance setting up LDAP to RH IdM.</td>\n",
       "      <td>ldap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02551788</td>\n",
       "      <td>Unable to update Ansible 2.7 to 2.8 - dependen...</td>\n",
       "      <td>upgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02552169</td>\n",
       "      <td>RFE - Unable to manage multiple scm sources in...</td>\n",
       "      <td>rfe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_number                                       case_summary     case_tags\n",
       "0    02551134                   Ansible Tower Installation Issue  installation\n",
       "1    02551460  Is there a way to provide permission to invent...           api\n",
       "2    02551667         Need assistance setting up LDAP to RH IdM.          ldap\n",
       "3    02551788  Unable to update Ansible 2.7 to 2.8 - dependen...       upgrade\n",
       "4    02552169  RFE - Unable to manage multiple scm sources in...           rfe"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_df[['case_number', 'case_summary', 'case_tags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_number', 'case_createdDate', 'case_product', 'case_summary',\n",
       "       'case_description', 'case_sbr', 'case_tags', 'case_type', 'case_origin',\n",
       "       'sbr_length', 'tag_length', 'targets', 'labels', 'text', 'x', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df.to_csv(f'{BASE}/ansible_labeled_dataset_visualize.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/msivanes/0Work/routing/garlock/data/interim/ansible_labeled_dataset_visualize.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{BASE}/ansible_labeled_dataset_visualize.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3796"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ans_df['case_tags'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['upgrade', 'registration', 'ldap', 'installation', 'tower_license', 'automation_hub', 'inventory', 'scm_update', 'api', 'rfe', 'windows', 'backup_restore', 'security', 'collections', 'execution_environments', 'ansible_analytics', 'ansible_builder', 'ansible_navigator'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
